{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPmCYy/P5vXPvjztHohXydJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lastinm/ml_hw_notebooks/blob/main/%D0%9B%D0%B0%D0%B1%D0%BE%D1%80%D0%B0%D1%82%D0%BE%D1%80%D0%BD%D0%B0%D1%8F_%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%B0_%E2%84%961_Apache_Spark_(MapReduce).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Подключение Google диска"
      ],
      "metadata": {
        "id": "2mMEY4GfW0_H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Для работы с текстовым файлом подключим google диск."
      ],
      "metadata": {
        "id": "FzqY1qWfZUSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Подключаем Google Drive\n",
        " from google.colab import drive\n",
        " drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRJuboDhXXcm",
        "outputId": "d6f8a372-a9af-42c9-bbcc-6f3c89f4722b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задание 1\n",
        "\n",
        "Используя Apache Spark (MapReduce), реализовать программу для подсчета количества слов в тексте, который представляет собой некоторое количество строк, единственный разделитель между словами – пробел."
      ],
      "metadata": {
        "id": "p7vrYGuQcdzi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Решение"
      ],
      "metadata": {
        "id": "9yS8_7VZdsQ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*MapReduce в контексте Spark*\n",
        "\n",
        "**MapReduce** — это модель программирования, которая изначально была предложена Google для обработки и генерации больших наборов данных. Она разделяет задачу обработки на две основные фазы:\n",
        "\n",
        "**Map**: Данные обрабатываются функцией Map, которая берет набор данных и преобразует его в набор пар \"ключ-значение\".\n",
        "**Reduce**: Затем функция Reduce принимает эти пары ключей и значений, группирует их и производит итоговые результаты."
      ],
      "metadata": {
        "id": "7zqezYS7dk8y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Загрузка данных\n",
        "\n",
        "Есть текстовый файл со сказкой А.С. Пушкина \"Золотая рыбка\", содержащий строки текста. Мы будем загружать содержимое этого файла в RDD."
      ],
      "metadata": {
        "id": "fK-npo-na15Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijX5-NiWXJB8"
      },
      "outputs": [],
      "source": [
        "# Импортируем необходимые библиотеки\n",
        "from pyspark import SparkConf, SparkContext"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Загружаем текстовый файл\n",
        "text_file = sc.textFile(\"/content/drive/MyDrive/Data/Пушкин А.С. - Сказка о рыбаке и рыбке.txt\")"
      ],
      "metadata": {
        "id": "C7hiGp_PbKPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Инициализация SparkContext\n",
        "\n",
        "Инициализируем контекст Spark. Это основа для работы с RDD (Resilient Distributed Dataset)."
      ],
      "metadata": {
        "id": "wAV54GNRanlK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Создаем конфигурацию Spark\n",
        "conf = SparkConf().setAppName(\"WordCount\").setMaster(\"local[*]\")\n",
        "sc = SparkContext(conf = conf)"
      ],
      "metadata": {
        "id": "etZnUIpVaHet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Подсчет слов"
      ],
      "metadata": {
        "id": "fyvvF7P_hW21"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для понимания, как работает Spark, рассмотрим простой пример подсчета слов, который можно реализовать с использованием концепций MapReduce.\n",
        "\n",
        "Map: Преобразуем текст в слова, создавая пары \"слово, 1\".\n",
        "\n",
        "Reduce: Суммируем значения для каждого слова, чтобы получить его общее количество."
      ],
      "metadata": {
        "id": "lBvcLsA2eaL7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Преобразуем текст в слова\n",
        "words = text_file.flatMap(lambda line: line.split(\" \"))\n",
        "\n",
        "# Преобразуем каждую строку строку со словом в пару \"слово\" и цифра 1\n",
        "list_words = words.map(lambda word: (word, 1))\n",
        "list_words.take(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vVlTFG4byg1",
        "outputId": "6a4c53ce-51b8-4a17-e484-ae60c7010ede"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Жил', 1), ('старик', 1), ('со', 1), ('своею', 1), ('старухой', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Подсчитываем количество слов\n",
        "word_counts = list_words.reduceByKey(lambda a, b: a + b)\n",
        "word_counts.take(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hoqHX1me1LM",
        "outputId": "ce018a65-b401-45d3-804b-d6017749f187"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Жил', 1),\n",
              " ('старухой', 1),\n",
              " ('У', 2),\n",
              " ('самого', 1),\n",
              " ('синего', 1),\n",
              " ('моря;', 1),\n",
              " ('Они', 1),\n",
              " ('землянке', 1),\n",
              " ('Ровно', 1),\n",
              " ('тридцать', 2)]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задание 2\n",
        "\n",
        "Используя Apache Spark (DataFrame), реализовать программу для подсчета количества слов в тексте, которые представляет собой некоторое количество строк, единственный разделитель между словами – пробел."
      ],
      "metadata": {
        "id": "XlTK-R2vf8tB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Решение"
      ],
      "metadata": {
        "id": "7caP8Ih3Xqt1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DataFrame** в **Apache Spark** — это распределенная коллекция данных, организованных в виде таблицы. Он аналогичен таблицам в реляционных базах данных и предоставляет возможность выполнять операции SQL."
      ],
      "metadata": {
        "id": "3KDArdR_XiuE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Загрузка данных\n",
        "\n",
        "Есть текстовый файл со сказкой А.С. Пушкина \"Золотая рыбка\", содержащий строки текста. Мы будем загружать содержимое этого файла в DataFrame."
      ],
      "metadata": {
        "id": "cbib0cU7Xy_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Импорт необходимых библиотек\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import explode, split, col\n",
        "\n",
        "# Создание SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Загрузка текстового файла в DataFrame\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "VkmrSRx6YOrV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка текстового файла в DataFrame\n",
        "# При загрузке текстового файла каждая строка файла будет представлена как отдельная запись\n",
        "df = spark.read.text('/content/drive/MyDrive/Data/Пушкин А.С. - Сказка о рыбаке и рыбке.txt')\n",
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WtW3cAXYell",
        "outputId": "521c3998-0d59-43dc-f2cc-926aff084a11"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|               value|\n",
            "+--------------------+\n",
            "|Жил старик со сво...|\n",
            "|У самого синего м...|\n",
            "|Они жили в ветхой...|\n",
            "|Ровно тридцать ле...|\n",
            "|Старик ловил нево...|\n",
            "+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Подсчет слов"
      ],
      "metadata": {
        "id": "z3Xq3YwfaD3p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Разделение строк на слова, используя пробел как разделитель\n",
        "# explode создает отдельные строки для каждого слова\n",
        "words_df = df.select(explode(split(col(\"value\"), \" \")).alias(\"word\"))\n",
        "words_df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QNVEilfZ_H6",
        "outputId": "98590fd9-8064-4703-beb0-cd84fc4cbcca"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+\n",
            "|    word|\n",
            "+--------+\n",
            "|     Жил|\n",
            "|  старик|\n",
            "|      со|\n",
            "|   своею|\n",
            "|старухой|\n",
            "+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Считать вхождения каждого слова\n",
        "word_count_df = words_df.groupBy(\"word\").count()\n",
        "\n",
        "# Показать результат\n",
        "print(\"Количество вхождений каждого слова:\")\n",
        "word_count_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ienMZ4o0amEn",
        "outputId": "1f33dd5e-3624-4770-c214-114aab99ecb9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество вхождений каждого слова:\n",
            "+-----------+-----+\n",
            "|       word|count|\n",
            "+-----------+-----+\n",
            "|       себя|    1|\n",
            "|     баба».|    1|\n",
            "|         Уж|    3|\n",
            "|     теперь|    2|\n",
            "|       чтоб|    1|\n",
            "|     просит|    1|\n",
            "|   душенька|    2|\n",
            "|   старуху,|    1|\n",
            "|     плечах|    1|\n",
            "|          —|    8|\n",
            "|прикрикнула|    1|\n",
            "|    невежа!|    1|\n",
            "|    поперек|    1|\n",
            "|        так|    1|\n",
            "|       Чай,|    1|\n",
            "|    сказала|    1|\n",
            "|    неделя,|    2|\n",
            "|    умеешь,|    1|\n",
            "|   молвить.|    1|\n",
            "|          У|    2|\n",
            "+-----------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задание 3\n",
        "\n",
        "Доработайте программу из задания 2: учитывайте, что одно слово может быть записано в разном регистре (Word, word, WORD – одно слово), в тексте могут присутствовать знаки пунктуации, а также то, что количество пробелов между словами может быть больше одного."
      ],
      "metadata": {
        "id": "n8Q68nQUbCTa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Решение"
      ],
      "metadata": {
        "id": "STYnpSlGbIAB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Импорт дополнительных модулей"
      ],
      "metadata": {
        "id": "aYPZsMR1bgz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import lower, regexp_replace, count, desc"
      ],
      "metadata": {
        "id": "iLvmCimkblYv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Предобработка исходного датафрейма"
      ],
      "metadata": {
        "id": "ernYv4e9byaC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Нормализация текста:\n",
        "# - Приведение к нижнему регистру\n",
        "# - Удаление знаков пунктуации с помощью регулярных выражений\n",
        "# Регулярное выражение без учета дефиса и частиц\n",
        "#normalized_df = df.select(regexp_replace(lower(col(\"value\")), \"[^а-яА-ЯёЁ\\\\s]\", \"\").alias(\"normalized_value\"))\n",
        "# Учли, что слова могут содержать дефис для отделения частиц\n",
        "normalized_df = df.select(regexp_replace(lower(col(\"value\")), \"[^a-zA-Zа-яА-ЯёЁ\\\\s-]\", \"\").alias(\"normalized_value\"))\n",
        "\n",
        "normalized_df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5siepw5bwD8",
        "outputId": "924239ec-7d2b-4561-b86c-0209e1ffc738"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|    normalized_value|\n",
            "+--------------------+\n",
            "|жил старик со сво...|\n",
            "|у самого синего моря|\n",
            "|они жили в ветхой...|\n",
            "|ровно тридцать ле...|\n",
            "|старик ловил нево...|\n",
            "+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Разделение строк на слова, учитывая произвольное количество пробелов\n",
        "words_df = normalized_df.select(explode(split(col(\"normalized_value\"), \"\\\\s+\")).alias(\"word\"))\n",
        "words_df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0UXo9-gcuHB",
        "outputId": "0cc8e1ad-cea7-473b-f998-0f100b75fc41"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+\n",
            "|    word|\n",
            "+--------+\n",
            "|     жил|\n",
            "|  старик|\n",
            "|      со|\n",
            "|   своею|\n",
            "|старухой|\n",
            "+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Удаление пустых строк (если они остались)\n",
        "words_df = words_df.filter(col(\"word\") != \"\")"
      ],
      "metadata": {
        "id": "UhayhtpQc6Xy"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Подсчет вхождений каждого слова\n",
        "word_count_df = words_df.groupBy(\"word\").count()\n",
        "word_count_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhZOjP1tc-oT",
        "outputId": "7535cea3-e12d-4b6a-9b03-1f0016914406"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----+\n",
            "|       word|count|\n",
            "+-----------+-----+\n",
            "|       себя|    1|\n",
            "|    простую|    1|\n",
            "|   выпросил|    2|\n",
            "|  насмешишь|    1|\n",
            "|     теперь|    2|\n",
            "|      тиной|    1|\n",
            "|       чтоб|    2|\n",
            "|     просит|    1|\n",
            "|   душенька|    2|\n",
            "|     плечах|    1|\n",
            "|прикрикнула|    1|\n",
            "|        так|    5|\n",
            "|    поперек|    1|\n",
            "|    сказала|    1|\n",
            "|раскололось|    2|\n",
            "|    поделом|    1|\n",
            "|      пряла|    1|\n",
            "|     третий|    1|\n",
            "|      хочет|    6|\n",
            "|     служат|    1|\n",
            "+-----------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Топ-10 самых часто встречаемых слов"
      ],
      "metadata": {
        "id": "fVucHKeZdTnq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Топ-10 самых часто встречаемых слов\n",
        "top_10_words = word_count_df.orderBy(desc(\"count\")).limit(10)\n",
        "top_10_words.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1MvmgocdEgU",
        "outputId": "b148ee75-f701-49fe-e758-62792792dc54"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+\n",
            "|   word|count|\n",
            "+-------+-----+\n",
            "|     не|   29|\n",
            "|      с|   21|\n",
            "|  рыбка|   19|\n",
            "|      в|   17|\n",
            "|старуха|   17|\n",
            "|     он|   17|\n",
            "|      к|   16|\n",
            "| старик|   16|\n",
            "|     на|   14|\n",
            "|      и|   14|\n",
            "+-------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Слово, которое встречается чаще всего"
      ],
      "metadata": {
        "id": "V5DdPgzcdyXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Слово, которое встречается чаще всего\n",
        "most_frequent_word = word_count_df.orderBy(desc(\"count\")).first()\n",
        "most_frequent_word"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYZfjNDzd3tb",
        "outputId": "24f46dea-a01d-476c-9969-3bf8be206627"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Row(word='не', count=29)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Слово, которое встречается реже всего"
      ],
      "metadata": {
        "id": "3fE9SVZ9eOI2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Слово, которое встречается реже всего\n",
        "least_frequent_word = word_count_df.orderBy(\"count\").first()\n",
        "least_frequent_word"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z079uR81eWQP",
        "outputId": "bb935595-a07b-4efe-f159-f768e6f1f898"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Row(word='себя', count=1)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Средняя встречаемость слов в тексте"
      ],
      "metadata": {
        "id": "zgSRTm5ReyJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Средняя встречаемость слов\n",
        "average_frequency = word_count_df.agg({\"count\": \"avg\"}).first()[0]\n",
        "average_frequency"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aemam48EexWO",
        "outputId": "2e26b4db-e313-4b4e-c113-f25ae955ef84"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.4205128205128204"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Общее число уникальных слов"
      ],
      "metadata": {
        "id": "Bs-MoEZBe-kw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Общее число уникальных слов\n",
        "unique_word_count = word_count_df.count()\n",
        "unique_word_count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZR5WABomfE9d",
        "outputId": "535b68e3-5a3a-4095-86c9-d0714afce981"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "390"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Общее число слов в тексте"
      ],
      "metadata": {
        "id": "Cw8l8qGmfLsn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Общее количество слов в тексте\n",
        "total_word_count = words_df.count()\n",
        "total_word_count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4deOGNY6fNxP",
        "outputId": "a48d5670-4dc1-4723-a476-22cb8f0168fe"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "944"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    }
  ]
}